<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{network scale-up}
-->
Analyzing network scale-up data using the **networkreporting** package
=====================================================================

Introduction
------------

The **networkreporting** package has several tools for analyzing survey data
that have been collected using the network scale-up method.

This introduction will assume that you already have the **networkreporting**
package installed. If you don't, please refer to the introductory vignette 
("getting started") for instructions on how to do this. 

Review of the network scale-up method
-------------------------------------

For the purposes of this vignette, we'll assume that we have conducted a survey
using network scale-up questions to try and estimate the size of an important
population.  Analytically, this involves two main steps: 

* step 1: we need to estimate the size of the survey respondents' personal
  networks (their *degrees*)
* step 2: we need to use the estimated degrees to produce estimates for the
  size of the hidden population.

We'll quickly review each of these steps, and then we'll show how to use
the package to carry the estimation out.

### Step 1: estimating network sizes

Here, we will use the *known population* estimator for respondents' degrees.
(TODO CITE). In order to estimate the degree of the $i$ th survey respondent,
we use

$$
\begin{align}
\label{eqn:kpdegree}
\hat{d_i} = \sum_{j=1}^{K} y_{ij} ~ 
\frac{N}{\sum_{j=1}^{K} N_j},
\end{align}
$$

where $N$ is the total size of the population, $N_j$ is the size of
the $j$ th population of known size, and $y_{ij}$ is the number of connections
that survey respondent $i$ reports between herself and members of the $j$ th
population of known size.

### Step 2: estimating hidden population sizes

Once we have the estimates of the respondents' degrees, we use them to produce
an estimate for the size of the hidden population:

$$
\begin{align}
\label{eqn:nsum}
\hat{N}_h = \frac{ \sum_{i \in s} y_{ih} }{ \sum_{i \in s} \hat{d_i} },
\end{align}
$$

where $N_h$ is the size of the population of interest (which we want to
estimate), $s$ is the set of respondents in our sample, and $\hat{d_i}$ is the
estimate of the size of respondent $i$'s degree, obtained using the known
population method.

Preparing data
--------------
The first step is to prepare the data.  We'll assume that we start with two
datasets: the first is a survey containing information collected from
respondents about their personal networks; the second is information about the
sizes of several populations.

The example data for this vignette are provided with the `networkreporting`
package, and can be loaded by typing

```{r, message=FALSE}
library(networkreporting)
library(plyr)
library(ggplot2) # we'll use qplot from ggplot2 for plots
theme_set(theme_minimal())

data(hhsurvey) # this is a demo dataset included with the package
```

The demo data include two datasets: one has all of the responses from a
network scale-up survey, and the other has the known population sizes for
use with the known population estimator.

### Preparing the known population data


The demo known population data are in `knownpop.dat`: 

```{r}
knownpop.dat
```

`knownpop.dat` is very simple: one column has a name for each known population,
and the other has its toal size. We expect that users will typically start with
a small dataset like this one. When using the `networkreporting` package, it is
more useful to have a vector whose entries are known population sizes and whose
names are the known population names. The `df.to.kpvec` function makes it easy
for us to create it:

```{r}
kp.vec <- df.to.kpvec(knownpop.dat, kp.var="known.popn", kp.value="size")

kp.vec
```

Finally, we also need to know the total size of the population we are making
estimates about. In this case, let's assume that we're working in a country of
10 million people:

```{r}
# total size of the population
tot.pop.size <- 10e6
```

TODO -- attach known population example

### Preparing the survey data

Now let's take a look at the demo survey dataset, which is called
`example.survey`:

```{r}
head(example.survey)
```

The columns fall into one of a few categories:

* an id variable for each respondent: `id`
* information related to the sampling design of the survey: `cluster`, `region`, and `indweight`. 
* demographic characteristics of the respondents: `sex` and `age.cat` 
* responses to questiona bout populations whose total size is known: `widower`, ...,
`mukandayisenga`
* questions about hidden populations: `died`, ..., `clients` 

#### Topcoding

Many network scale-up studies have topcoded the responses to the aggregate
relational data questions. This means that researchers considered any responses
above a certain value, called the topcode, to be implausible. Before proceeding
with the analysis, they substitute the maximum plausible value in for the
implausible ones. For example, in many studies, researchers assumed that
responses more than 30 are implausible, so they replaced responses with the
value 31 or higher with the value 30 before conducting their analysis.

We won't discuss whether or not this is advisable here, but this is currently a
common practice in scale-up studies. If you wish to follow it, you can use the
`topcode.data` function. As an example, let's topcode the responses to
the questions about populations of known size to the value 30. First, we'll
examine the distribution of the responses before topcoding:

```{r}
## make a vector with the list of known population names from
## our dataset of known population totals
known.popn.vars <- paste(knownpop.dat$known.popn)

## before topcoding: max. response for several popns is > 30
summary(example.survey[,known.popn.vars])
```

Several populations, including `widower`, `male.community.health`, `teacher`,
`woman.smoke`, `muslim`, and `incarcerated` have maximum values that are very
high. (It turns out that 95 is the highest value that could be recorded during
the interviews; if respondents said that they were connected to more than 95
people in the group, the interviewers wrote 95 down.)

Now we use the `topcode.data` function to topcode all of the responses
at 30:

```{r}
example.survey <- topcode.data(example.survey,
                               vars=known.popn.vars,
                               max=30)

## after topcoding: max. response for all popns is 30
summary(example.survey[,known.popn.vars])
```

If you look at the help page for `topcode.data`, you'll see that it can also
handle situations where the variables can take on special codes for missing
values, refusals, and so forth. 

Estimating network sizes
------------------------

Now that we have finished preparing the data, we turn to esimating the sizes of
each respondent's personal network.  To do this using the known population
estimator, we use the `kp.degree.estimator` function:

```{r, tidy=FALSE}
d.hat <- kp.degree.estimator(survey.data=example.survey,
                             known.popns=kp.vec,
                             total.popn.size=tot.pop.size,
                             missing="complete.obs")

summary(d.hat)
```

Note that the function reports that it's working in absolute numbers (instead
of, for example, proportions.)  We can examine the results with a histogram

```{r}
qplot(d.hat, binwidth=25)
```

Let's attach the degree estimates to the dataframe to keep track of them:

```{r}
example.survey$d.hat <- d.hat
```

### Missing data in known population questions

TODO

Internal valididty checks
-------------------------

In order to run internal validation checks, you can use the
`nsum.internal.validation` function. We specify that we wish to use only
complete observations (ie, we will remove rows that have any missing values
from our calculations).

```{r, tidy=FALSE}
iv.result <- nsum.internal.validation(survey.data=example.survey,
                                      known.popns=kp.vec,
                                      missing="complete.obs",
                                      killworth.se=TRUE,
                                      total.popn.size=tot.pop.size,
                                      kp.method=TRUE,
                                      return.plot=TRUE)
```

Now `iv.result` is a list that has a summary of the results in the entry `results`

```{r}
iv.result$results
```

Since we passed the argument `return.plot=TRUE` to the function, we also get a plot:
```{r}
print(iv.result$plot)
```

This is a `ggplot2` object, so we can customize it if we want. As a very simple 
example, we can change the title:

```{r}
print(iv.result$plot + ggtitle("internal validation checks"))
```

Estimating hidden population size
---------------------------------

Now that we have estimated degrees, we can use them to produce estimates of the
populations we're interested in. Here, we'll take the example of injecting drug
users, `idu`

```{r, tidy=FALSE}
idu.est <- nsum.estimator(survey.data=example.survey,
                          d.hat.vals=d.hat,
                          total.popn.size=tot.pop.size,
                          y.vals="idu",
                          missing="complete.obs")
```

Note that we had to specify that we should use only rows in our dataset with no
missing values through the `missing = "complete.obs"` option, and also that we
had to pass in the total population size using the `total.popn.size` option.
The resulting estimate is

```{r}
idu.est
```

This returns the estimate, and also the numerator and denominator used to
compute it.

Variance estimation
-------------------

In order to estimate the sampling uncertainty of our estimated totals, we can
use the rescaled bootstrap technique that is in the `networkreporting` package.
In order to do so, we need to be able to describe the sampling design of our
study. In particular, we need to be able to describe the stratifcation (if any)
and the primary sampling units used in the study.

```{r, tidy=FALSE}
idu.est <- bootstrap.estimates(## this describes the sampling design of the
                               ## survey; here, the PSUs are given by the
                               ## variable cluster, and the strata are given
                               ## by the variable region
                               survey.design = ~ cluster + strata(region),
                               ## the number of bootstrap resamples to obtain
                               ## (NOTE: in practice, you should use more than 100.
                               ##  this keeps building the package relatively fast)
                               num.reps=100,
                               ## this is the name of the function
                               ## we want to use to produce an estimate
                               ## from each bootstrapped dataset
                               estimator.fn="nsum.estimator",
                               ## these are the sampling weights
                               weights="indweight",
                               ## this is the name of the type of bootstrap
                               ## we wish to use
                               bootstrap.fn="rescaled.bootstrap.sample",
                               ## our dataset
                               survey.data=example.survey,
                               ## other parameters we need to pass
                               ## to the nsum.estimator function
                               d.hat.vals=d.hat,
                               total.popn.size=tot.pop.size,
                               y.vals="idu",
                               missing="complete.obs")
```

By default, `bootstrap.estimates` produces a list with `num.reps` entries; each
entry is the result of calling the estimator function on one bootstrap
resample.  We can write a bit of code that will help us put all of these
results together, for plotting and summarizing

```{r}
## combine the estimates together in one data frame
## (bootstrap.estimates gives us a list)
all.idu.estimates <- ldply(idu.est,
                           function(x) { data.frame(estimate=x$estimate) })
```

We can examine the summarized results with a histogram or with `summarize`.

```{r}
## look at a histogram of the results
qplot(all.idu.estimates$estimate, binwidth=50)

## summarize the results
summary(all.idu.estimates$estimate)
```

Attaching known population totals to the dataframe
--------------------------------------------------

Several of the functions we demonstrated above required us to pass in
the vector containing the known population sizes and also the size of
the total population.  We can avoid this step by attaching these two
pieces of information to the survey dataframe using the `add.kp` function:

```{r}
example.survey <- add.kp(example.survey, kp.vec, tot.pop.size)

d.hat.new <- kp.degree.estimator(survey.data=example.survey,
                                 # we don't need this anymore, since we
                                 # them to survey.data's attributes using add.kp
                                 #known.popns=kp.vec,
                                 #total.popn.size=tot.pop.size,
                                 missing="complete.obs")

summary(d.hat.new)
```

This is exactly the same result we obtained before.

